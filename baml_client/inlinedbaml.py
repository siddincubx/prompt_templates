# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\r\n\r\n// Using the new OpenAI Responses API for enhanced formatting\r\nclient<llm> CustomGPT5 {\r\n  provider openai-responses\r\n  options {\r\n    model \"gpt-5\"\r\n    api_key env.OPENAI_API_KEY\r\n  }\r\n}\r\n\r\nclient<llm> CustomGPT5Mini {\r\n  provider openai-responses\r\n  retry_policy Exponential\r\n  options {\r\n    model \"gpt-5-mini\"\r\n    api_key env.OPENAI_API_KEY\r\n  }\r\n}\r\n\r\n// Openai with chat completion\r\nclient<llm> CustomGPT5Chat {\r\n  provider openai\r\n  options {\r\n    model \"gpt-5\"\r\n    api_key env.OPENAI_API_KEY\r\n  }\r\n}\r\n\r\n// Latest Anthropic Claude 4 models\r\nclient<llm> CustomOpus4 {\r\n  provider anthropic\r\n  options {\r\n    model \"claude-opus-4-1-20250805\"\r\n    api_key env.ANTHROPIC_API_KEY\r\n  }\r\n}\r\n\r\nclient<llm> CustomSonnet4 {\r\n  provider anthropic\r\n  options {\r\n    model \"claude-sonnet-4-20250514\"\r\n    api_key env.ANTHROPIC_API_KEY\r\n  }\r\n}\r\n\r\nclient<llm> CustomHaiku {\r\n  provider anthropic\r\n  retry_policy Constant\r\n  options {\r\n    model \"claude-3-5-haiku-20241022\"\r\n    api_key env.ANTHROPIC_API_KEY\r\n  }\r\n}\r\n\r\n// Example Google AI client (uncomment to use)\r\nclient<llm> CustomGemini {\r\n  provider google-ai\r\n  options {\r\n    model \"gemini-2.0-flash\"\r\n    api_key env.GEMINI_API_KEY\r\n  }\r\n}\r\n\r\n// Example AWS Bedrock client (uncomment to use)\r\n// client<llm> CustomBedrock {\r\n//   provider aws-bedrock\r\n//   options {\r\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\r\n//     region \"us-east-1\"\r\n//     // AWS credentials are auto-detected from env vars\r\n//   }\r\n// }\r\n\r\n// Example Azure OpenAI client (uncomment to use)\r\n// client<llm> CustomAzure {\r\n//   provider azure-openai\r\n//   options {\r\n//     model \"gpt-5\"\r\n//     api_key env.AZURE_OPENAI_API_KEY\r\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\r\n//     api_version \"2024-10-01-preview\"\r\n//   }\r\n// }\r\n\r\n// Example Vertex AI client (uncomment to use)\r\n// client<llm> CustomVertex {\r\n//   provider vertex-ai\r\n//   options {\r\n//     model \"gemini-2.5-pro\"\r\n//     location \"us-central1\"\r\n//     // Uses Google Cloud Application Default Credentials\r\n//   }\r\n// }\r\n\r\n// Example Ollama client for local models (uncomment to use)\r\n// client<llm> CustomOllama {\r\n//   provider openai-generic\r\n//   options {\r\n//     base_url \"http://localhost:11434/v1\"\r\n//     model \"llama4\"\r\n//     default_role \"user\" // Most local models prefer the user role\r\n//     // No API key needed for local Ollama\r\n//   }\r\n// }\r\n\r\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\r\nclient<llm> CustomFast {\r\n  provider round-robin\r\n  options {\r\n    // This will alternate between the two clients\r\n    strategy [CustomGPT5Mini, CustomHaiku]\r\n  }\r\n}\r\n\r\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\r\nclient<llm> OpenaiFallback {\r\n  provider fallback\r\n  options {\r\n    // This will try the clients in order until one succeeds\r\n    strategy [CustomGPT5Mini, CustomGPT5]\r\n  }\r\n}\r\n\r\n// https://docs.boundaryml.com/docs/snippets/clients/retry\r\nretry_policy Constant {\r\n  max_retries 3\r\n  strategy {\r\n    type constant_delay\r\n    delay_ms 200\r\n  }\r\n}\r\n\r\nretry_policy Exponential {\r\n  max_retries 2\r\n  strategy {\r\n    type exponential_backoff\r\n    delay_ms 300\r\n    multiplier 1.5\r\n    max_delay_ms 10000\r\n  }\r\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.212.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "template.baml": "class Template{\r\n    text string\r\n    variables string[]\r\n    title string\r\n}\r\n\r\nfunction CreateTemplate(requirement : string) -> Template{\r\n    client CustomGemini\r\n    prompt #\"\r\n        Create a prompt for fulfilling the requirement:\r\n        {{ requirement }}\r\n\r\n        The prompt generated must be in template format that includes placeholders for variables that can be filled in later.\r\n        The prompt generated is expected to be in EJS format.\r\n\r\n        IMPORTANT: DO NOT provide the template for requirement itself but generate a prompt that will fulfill this requirement.\r\n        \r\n        Provide the template text and a list of variable names used in the template. \r\n        Think about the requirement carefully and find the ambiguous entities. \r\n        These entities should be converted into variables in the template.\r\n        BE CAREFUL TO NOT CREATE DUPLICATE VARIABLES. DO NOT CREATE VARIABLES THAT ARE REDUNDANT.\r\n\r\n        IMPORTANT: DO NOT provide the template for requirement itself but generate a prompt to fulfill this requirement.\r\n\r\n        for example:\r\n        Requirement: I want to generate personalized email invitations for a conference.\r\n        Output: \r\n        Generate a personalized email invitation for the <%= conferenceName %> conference, taking place from <%= startDate %> to <%= endDate %> at <%= location %>. \r\n        The email should be addressed to <%= recipientName %>.  Use a friendly and professional tone.\r\n        Begin with a captivating subject line: '<%= subjectLine %>'\r\n        In the email body, briefly introduce the conference, highlighting its key themes: <%= conferenceThemes %>. Mention that <%= speakerName %> will be a keynote speaker.\r\n        Personalize the invitation by mentioning <%= personalizedMessage %>. \r\n        Include a call to action, encouraging the recipient to register for the conference via the following link: <%= registrationLink %>.  Offer an early bird discount if they register before <%= earlyBirdDeadline %>, specifying the discount as <%= earlyBirdDiscount %>.\r\n        Include a brief agenda summary: <%= agendaSummary %>. \r\n        Conclude the email with a professional closing and signature from <%= senderName %> (<%= senderTitle %>).\r\n        Ensure the email is visually appealing and easy to read.\r\n        {{ ctx.output_format }}\r\n    \"#\r\n    \r\n}\r\n\r\ntest template_conference_email_invitation {\r\n    functions [CreateTemplate]\r\n    args {\r\n        requirement #\"\r\n            I want to generate personalized email invitations for a conference. \r\n        \"#\r\n    }\r\n}\r\n\r\ntest template_apologise_mistake_chat_msg {\r\n    functions [CreateTemplate]\r\n    args {\r\n        requirement #\"\r\n            I want to generate a personalized apology message for a mistake made in a chat conversation.\r\n        \"#\r\n    }\r\n}\r\ntest template_product_description {\r\n    functions [CreateTemplate]\r\n    args {\r\n        requirement #\"\r\n            I want to generate an engaging product descriptions for an e-commerce website. \r\n        \"#\r\n    }\r\n}",
}

def get_baml_files():
    return _file_map